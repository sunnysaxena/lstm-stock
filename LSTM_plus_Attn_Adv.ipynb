{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnysaxena/lstm-stock/blob/main/LSTM_plus_Attn_Adv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HPoI9N6En71B"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow -qqq\n",
        "# !pip install keras -qqq\n",
        "# !pip install yfinance -qqq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(\"TensorFlow Version: \", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCjjaDB2oDJi",
        "outputId": "192e3505-977c-4480-8217-0190311a0ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version:  2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch AAPL data\n",
        "# aapl_data = yf.download('AAPL', start='2020-01-01', end='2024-01-01')\n",
        "\n",
        "aapl_data = pd.read_csv('https://raw.githubusercontent.com/sunnysaxena/lstm-stock/main/ongc.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "aapl_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f_5OSpdNoJmV",
        "outputId": "22285d49-9af6-4248-fe50-739eb2989e23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date    Open    High     Low   Close  Volume\n",
              "0  2020-01-01  128.75  128.90  126.85  127.45       0\n",
              "1  2020-01-02  127.65  128.65  127.10  128.05       0\n",
              "2  2020-01-03  131.00  133.40  128.05  128.45       0\n",
              "3  2020-01-06  129.70  129.80  125.10  126.25       0\n",
              "4  2020-01-07  125.60  127.70  125.40  125.75       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44b5c0d4-0be5-4372-8ada-6a3696ad4c9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>128.75</td>\n",
              "      <td>128.90</td>\n",
              "      <td>126.85</td>\n",
              "      <td>127.45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>127.65</td>\n",
              "      <td>128.65</td>\n",
              "      <td>127.10</td>\n",
              "      <td>128.05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>131.00</td>\n",
              "      <td>133.40</td>\n",
              "      <td>128.05</td>\n",
              "      <td>128.45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>129.70</td>\n",
              "      <td>129.80</td>\n",
              "      <td>125.10</td>\n",
              "      <td>126.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>125.60</td>\n",
              "      <td>127.70</td>\n",
              "      <td>125.40</td>\n",
              "      <td>125.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44b5c0d4-0be5-4372-8ada-6a3696ad4c9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44b5c0d4-0be5-4372-8ada-6a3696ad4c9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44b5c0d4-0be5-4372-8ada-6a3696ad4c9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24fb7298-e6b7-4fba-9564-87c10e55caae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24fb7298-e6b7-4fba-9564-87c10e55caae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24fb7298-e6b7-4fba-9564-87c10e55caae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "aapl_data",
              "summary": "{\n  \"name\": \"aapl_data\",\n  \"rows\": 994,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 994,\n        \"samples\": [\n          \"2023-09-11\",\n          \"2022-02-08\",\n          \"2022-04-11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.692553622130646,\n        \"min\": 59.4,\n        \"max\": 209.5,\n        \"num_unique_values\": 761,\n        \"samples\": [\n          138.75,\n          113.5,\n          90.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.85269086662919,\n        \"min\": 63.0,\n        \"max\": 212.0,\n        \"num_unique_values\": 821,\n        \"samples\": [\n          143.15,\n          69.1,\n          77.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.489980035599835,\n        \"min\": 50.0,\n        \"max\": 205.35,\n        \"num_unique_values\": 790,\n        \"samples\": [\n          140.65,\n          89.5,\n          94.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.6597786126653,\n        \"min\": 60.0,\n        \"max\": 208.3,\n        \"num_unique_values\": 833,\n        \"samples\": [\n          136.4,\n          197.8,\n          111.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "aapl_data.isnull().sum()\n",
        "\n",
        "# Filling missing values, if any\n",
        "aapl_data.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "id": "uicfUmH3hrN8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "aapl_data_scaled = scaler.fit_transform(aapl_data['Close'].values.reshape(-1,1))\n"
      ],
      "metadata": {
        "id": "3s36F4gMhtje"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(60, len(aapl_data_scaled)):\n",
        "    X.append(aapl_data_scaled[i-60:i, 0])\n",
        "    y.append(aapl_data_scaled[i, 0])"
      ],
      "metadata": {
        "id": "poWhQb3Lh7vN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(X) * 0.8)\n",
        "test_size = len(X) - train_size\n",
        "\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n"
      ],
      "metadata": {
        "id": "KbYI0J75iGic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "rIcgdJI3iVKW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# # Model initialization\n",
        "# model = Sequential()\n",
        "\n",
        "# # Adding the first LSTM layer\n",
        "# model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "\n",
        "# # Adding additional LSTM layers\n",
        "# model.add(LSTM(units=50, return_sequences=True))\n",
        "# model.add(LSTM(units=50))\n"
      ],
      "metadata": {
        "id": "d9ZNsLyOodPg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM layers\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=False))  # Only the last time step\n",
        "\n",
        "# Adding a Dense layer to match the output shape with y_train\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm8OU_RQpjHv",
        "outputId": "3bb09b8d-64ba-43a4-e82e-015c9805c97c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 14s 111ms/step - loss: 0.0365 - val_loss: 0.0032\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.0042 - val_loss: 9.2390e-04\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 0.0032 - val_loss: 8.0361e-04\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0031 - val_loss: 7.7579e-04\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 0.0029 - val_loss: 7.4448e-04\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 7.1939e-04\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0026 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0024 - val_loss: 9.5393e-04\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.0022 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0027 - val_loss: 0.0016\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.0024 - val_loss: 6.6427e-04\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0024 - val_loss: 6.5297e-04\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0020 - val_loss: 6.6714e-04\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0021 - val_loss: 6.4788e-04\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 7.0096e-04\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.0019 - val_loss: 6.0956e-04\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 6.1293e-04\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 5.9944e-04\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 9.1953e-04\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 5.8493e-04\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 7.1029e-04\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 6.7690e-04\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 7.9191e-04\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 7.3580e-04\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 5.0618e-04\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 8.8367e-04\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 5.2265e-04\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 4.9683e-04\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 7.6683e-04\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 8.0467e-04\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 7.3646e-04\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 5.4692e-04\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 4.0903e-04\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 4.8726e-04\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 5.7662e-04\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 8.6277e-04\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 7.5969e-04\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 4.1455e-04\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 6.9920e-04\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 9.3546e-04 - val_loss: 4.6184e-04\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 3.3332e-04\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8.3928e-04 - val_loss: 4.9960e-04\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8.8135e-04 - val_loss: 6.2846e-04\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8.8416e-04 - val_loss: 3.5958e-04\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8.1521e-04 - val_loss: 3.5548e-04\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7.3151e-04 - val_loss: 6.7820e-04\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 7.8965e-04 - val_loss: 3.5295e-04\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 9.3519e-04 - val_loss: 2.8880e-04\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 9.4231e-04 - val_loss: 4.0678e-04\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 7.6618e-04 - val_loss: 2.6557e-04\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.8960e-04 - val_loss: 3.6669e-04\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6.7913e-04 - val_loss: 2.3549e-04\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 6.4547e-04 - val_loss: 3.4843e-04\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 6.5177e-04 - val_loss: 3.9847e-04\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 7.0295e-04 - val_loss: 3.2329e-04\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 8.4229e-04 - val_loss: 8.4709e-04\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 7.6056e-04 - val_loss: 6.5763e-04\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.9253e-04 - val_loss: 5.4889e-04\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 7.7085e-04 - val_loss: 6.0600e-04\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8.2102e-04 - val_loss: 4.0874e-04\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.3218e-04 - val_loss: 4.4632e-04\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6.4064e-04 - val_loss: 2.0659e-04\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.0021e-04 - val_loss: 2.9584e-04\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.7468e-04 - val_loss: 2.2651e-04\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.8232e-04 - val_loss: 2.3853e-04\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6.3455e-04 - val_loss: 5.5899e-04\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6.1968e-04 - val_loss: 5.9870e-04\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.7611e-04 - val_loss: 2.5461e-04\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6.0313e-04 - val_loss: 3.0964e-04\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.7830e-04 - val_loss: 2.0853e-04\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.9470e-04 - val_loss: 1.9073e-04\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5.1865e-04 - val_loss: 1.8038e-04\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.2137e-04 - val_loss: 1.8495e-04\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.9162e-04 - val_loss: 3.6106e-04\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.8916e-04 - val_loss: 2.3241e-04\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6.2323e-04 - val_loss: 2.3158e-04\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.2466e-04 - val_loss: 1.8150e-04\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.3604e-04 - val_loss: 1.7591e-04\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.0328e-04 - val_loss: 1.7414e-04\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 4.9987e-04 - val_loss: 1.8962e-04\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.0186e-04 - val_loss: 3.8565e-04\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.8970e-04 - val_loss: 4.5176e-04\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.1737e-04 - val_loss: 1.8604e-04\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.4715e-04 - val_loss: 5.1359e-04\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6.0190e-04 - val_loss: 3.0993e-04\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5.2150e-04 - val_loss: 1.8760e-04\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.6422e-04 - val_loss: 2.4241e-04\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5.0834e-04 - val_loss: 2.0226e-04\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5.2655e-04 - val_loss: 5.9539e-04\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 5.6498e-04 - val_loss: 2.0667e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, AdditiveAttention, Permute, Reshape, Multiply\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM layers with return_sequences=True\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "\n",
        "# Adding self-attention mechanism\n",
        "# The attention mechanism\n",
        "attention = AdditiveAttention(name='attention_weight')\n",
        "# Permute and reshape for compatibility\n",
        "model.add(Permute((2, 1)))\n",
        "model.add(Reshape((-1, X_train.shape[1])))\n",
        "attention_result = attention([model.output, model.output])\n",
        "multiply_layer = Multiply()([model.output, attention_result])\n",
        "# Return to original shape\n",
        "model.add(Permute((2, 1)))\n",
        "model.add(Reshape((-1, 50)))\n",
        "\n",
        "# Adding a Flatten layer before the final Dense layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Final Dense layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGQQgDCap2Vk",
        "outputId": "82fbedcd-d57c-4a04-a266-e63075068c73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 4s 40ms/step - loss: 0.0279 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0022\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0012\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0014\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0035\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 9.2477e-04\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 9.0961e-04\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 8.6688e-04\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 8.4263e-04\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 8.4910e-04\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 9.4839e-04\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 9.5937e-04\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 9.1167e-04\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 8.8417e-04\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0013\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 9.6341e-04\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 9.8564e-04\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.6488e-04\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.8535e-04\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 9.1159e-04\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0015\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 8.2894e-04\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 6.7375e-04\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 7.5720e-04\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 6.8322e-04\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.4400e-04\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 9.9226e-04\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 6.5676e-04\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 5.7028e-04\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.7625e-04\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.4853e-04\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 5.5370e-04\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.3637e-04\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.2853e-04\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 6.4537e-04\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 5.5186e-04\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.0005e-04\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.1640e-04\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.8056e-04\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.6709e-04\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 5.9382e-04\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 4.6008e-04\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8.8406e-04 - val_loss: 5.3800e-04\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8.9612e-04 - val_loss: 6.1482e-04\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 9.3049e-04 - val_loss: 7.0688e-04\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.2462e-04\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8.8292e-04 - val_loss: 4.2116e-04\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 9.8071e-04 - val_loss: 6.1958e-04\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8.7912e-04 - val_loss: 4.2196e-04\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 5.3506e-04\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 9.1588e-04 - val_loss: 0.0014\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 9.6589e-04 - val_loss: 7.1891e-04\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8.2457e-04 - val_loss: 4.0944e-04\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.8488e-04 - val_loss: 4.5087e-04\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.5269e-04 - val_loss: 5.2926e-04\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.1832e-04 - val_loss: 4.3250e-04\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.6228e-04 - val_loss: 3.9745e-04\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.5130e-04 - val_loss: 3.7184e-04\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.6933e-04 - val_loss: 5.0043e-04\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8.5698e-04 - val_loss: 0.0017\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.6022e-04 - val_loss: 5.5382e-04\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7.5417e-04 - val_loss: 3.4698e-04\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.2647e-04 - val_loss: 3.3472e-04\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6.4412e-04 - val_loss: 3.3782e-04\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.8293e-04 - val_loss: 3.5847e-04\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.3377e-04 - val_loss: 4.4413e-04\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6.6427e-04 - val_loss: 3.6141e-04\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7.7504e-04 - val_loss: 9.4532e-04\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.4391e-04 - val_loss: 5.2267e-04\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6.2628e-04 - val_loss: 7.0442e-04\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7.8893e-04 - val_loss: 5.7407e-04\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.7104e-04 - val_loss: 2.9212e-04\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.8853e-04 - val_loss: 3.6759e-04\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.7262e-04 - val_loss: 3.1905e-04\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.6473e-04 - val_loss: 2.8926e-04\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.6455e-04 - val_loss: 2.7046e-04\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.6539e-04 - val_loss: 2.8797e-04\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5.4265e-04 - val_loss: 4.3737e-04\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.6311e-04 - val_loss: 2.6384e-04\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.0448e-04 - val_loss: 3.0449e-04\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.1401e-04 - val_loss: 0.0012\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6.0348e-04 - val_loss: 4.3714e-04\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.2584e-04 - val_loss: 3.5260e-04\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5.0465e-04 - val_loss: 2.8926e-04\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.0365e-04 - val_loss: 3.3043e-04\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.3436e-04 - val_loss: 3.0462e-04\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5.2245e-04 - val_loss: 3.7771e-04\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 5.0652e-04 - val_loss: 2.5669e-04\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5.1731e-04 - val_loss: 2.9868e-04\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 4.8487e-04 - val_loss: 4.6298e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# Adding Dropout and Batch Normalization\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "cNFHFfBXfUV0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "3k49GMiVfbBg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'data' is your preprocessed dataset\n",
        "train_size = int(len(aapl_data) * 0.8)\n",
        "train_data, test_data = aapl_data[:train_size], aapl_data[train_size:]"
      ],
      "metadata": {
        "id": "gZiDl-vsfgZ8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frXaTYdmkn82",
        "outputId": "fc35d1f6-9fcd-46a9-ec90-5e8ca226986f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 60, 50)            10400     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 60, 50)            20200     \n",
            "                                                                 \n",
            " permute (Permute)           (None, 50, 60)            0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 50, 60)            0         \n",
            "                                                                 \n",
            " permute_1 (Permute)         (None, 60, 50)            0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 60, 50)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1)                 0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 1)                 4         \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33605 (131.27 KB)\n",
            "Trainable params: 33603 (131.26 KB)\n",
            "Non-trainable params: 2 (8.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train and y_train are already defined and preprocessed\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbPtB69Ukz_J",
        "outputId": "4aee6d84-d473-4625-92b8-5c081318096d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 8s 42ms/step - loss: 0.7172 - val_loss: 0.3110\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3985 - val_loss: 0.2544\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2173 - val_loss: 0.2322\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1426 - val_loss: 0.2139\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.1138 - val_loss: 0.1970\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0909 - val_loss: 0.1743\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0809 - val_loss: 0.1703\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0739 - val_loss: 0.1387\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.1205\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0540 - val_loss: 0.1243\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0446 - val_loss: 0.0937\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0385 - val_loss: 0.1037\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0352 - val_loss: 0.0887\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0832\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0289 - val_loss: 0.0684\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0255 - val_loss: 0.0701\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0401\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0253 - val_loss: 0.0302\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0398\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0478\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0307\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0423\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0347\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0209\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 0.0267\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0111\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0127\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0072\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0215\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0100\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0044\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0069\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0098\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0093\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0022\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 9.0664e-04\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0141\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0041\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0196\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0086\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 4.8864e-04\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 4.1280e-04\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0072\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0173\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0079\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0016\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0030\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0064\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0046\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 4.6956e-04\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0048\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0110\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 6.0690e-04\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0014\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0028\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0053\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0050\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0065\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0026\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0036\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 4.2504e-04\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0035\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0039\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 8.3778e-04\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0022\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0021\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 6.2872e-04\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 4.6760e-04\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0028\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 7.4510e-04\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0175\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 4.7140e-04\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 4.9191e-04\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0237\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 5.5190e-04\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 6.4450e-04\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 5.5706e-04\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0169\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0039\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 5.0998e-04\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0023\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 9.5232e-04\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0060\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0078\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0328\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0026\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 6.9831e-04\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0096\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0020\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0013\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 4.2553e-04\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 8.2088e-04\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0020\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0048\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 5.6188e-04\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0171\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0064\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 6.9260e-04\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 4.5806e-04\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 6.5669e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Usi7IDzsBt1",
        "outputId": "ccae9fc5-2a2c-4ac6-ad97-2cd77c49ace9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0056\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 4.5751e-04\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0049\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 3.1080e-04\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 5.7009e-04\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0057\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0027\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0034\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 4.8539e-04\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0095\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0399\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0047\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0104\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 5.1615e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "\n",
        "# Callback to save the model periodically\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Callback to reduce learning rate when a metric has stopped improving\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "# Callback for TensorBoard\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "# Callback to log details to a CSV file\n",
        "csv_logger = CSVLogger('training_log.csv')\n",
        "\n",
        "# Combining all callbacks\n",
        "callbacks_list = [early_stopping, model_checkpoint, reduce_lr, tensorboard, csv_logger]\n",
        "\n",
        "# Fit the model with the callbacks\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyf-0m6Ysc8w",
        "outputId": "379baf3b-3079-4020-dc92-dd3db73b2318"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 9.2769e-04 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "13/24 [===============>..............] - ETA: 0s - loss: 0.0130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0112 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0021 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 8.4342e-04 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0018 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0013 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0016 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0010 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0015 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 4.4653e-04 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0027 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0017 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 6.4989e-04 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0010 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0012 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0011 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0012 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0013 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0013 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0014 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_test and y_test to Numpy arrays if they are not already\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Ensure X_test is reshaped similarly to how X_train was reshaped\n",
        "# This depends on how you preprocessed the training data\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Now evaluate the model on the test data\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss: \", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh5F2eRVufDz",
        "outputId": "a6ed131c-b8d1-44e5-d471-77d4e94d8acd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 8ms/step - loss: 0.0086\n",
            "Test Loss:  0.008600901812314987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculating MAE and RMSE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(\"Mean Absolute Error: \", mae)\n",
        "print(\"Root Mean Square Error: \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dUI9KYQvEpw",
        "outputId": "ed1531d8-0705-4f0c-8260-87f0338b5166"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 5ms/step\n",
            "Mean Absolute Error:  0.08798147605706495\n",
            "Root Mean Square Error:  0.09274104856821185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Fetching the latest 60 days of AAPL stock data\n",
        "# data = yf.download('AAPL', period='60d', interval='1d')\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/sunnysaxena/lstm-stock/main/ongc_test.csv')\n",
        "\n",
        "# Selecting the 'Close' price and converting to numpy array\n",
        "closing_prices = data['Close'].values\n",
        "\n",
        "# Scaling the data\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(closing_prices.reshape(-1,1))\n",
        "\n",
        "# Since we need the last 60 days to predict the next day, we reshape the data accordingly\n",
        "X_latest = np.array([scaled_data[-60:].reshape(60)])\n",
        "\n",
        "# Reshaping the data for the model (adding batch dimension)\n",
        "X_latest = np.reshape(X_latest, (X_latest.shape[0], X_latest.shape[1], 1))\n",
        "\n",
        "# Making predictions for the next 4 candles\n",
        "predicted_stock_price = model.predict(X_latest)\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
        "\n",
        "print(\"Predicted Stock Prices for the next 4 days: \", predicted_stock_price)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIcCt2inxcE0",
        "outputId": "0eabfb76-93dc-4427-b22f-979a4587c6af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Stock Prices for the next 4 days:  [[270.7693]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ZuchR9V-FZv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Fetch the latest 60 days of AAPL stock data\n",
        "# data = yf.download('AAPL', period='60d', interval='1d')\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/sunnysaxena/lstm-stock/main/ongc_test.csv')\n",
        "\n",
        "# Select 'Close' price and scale it\n",
        "closing_prices = data['Close'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(closing_prices)\n",
        "\n",
        "# Predict the next 4 days iteratively\n",
        "predicted_prices = []\n",
        "current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days\n",
        "\n",
        "for i in range(4):  # Predicting 4 days\n",
        "    # Get the prediction (next day)\n",
        "    next_prediction = model.predict(current_batch)\n",
        "\n",
        "    # Reshape the prediction to fit the batch dimension\n",
        "    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
        "\n",
        "    # Append the prediction to the batch used for predicting\n",
        "    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
        "\n",
        "    # Inverse transform the prediction to the original price scale\n",
        "    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
        "\n",
        "print(\"Predicted Stock Prices for the next 4 days: \", predicted_prices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZjCPwjMyHep",
        "outputId": "18dea691-6f7f-4090-f462-6241c2d9a8d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted Stock Prices for the next 4 days:  [270.7693, 261.76144, 255.06328, 251.33768]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install mplfinance -qqq"
      ],
      "metadata": {
        "id": "L1Y0NoQAy8pC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mplfinance as mpf\n",
        "import matplotlib.dates as mpl_dates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'data' is your DataFrame with the fetched AAPL stock data\n",
        "# Make sure it contains Open, High, Low, Close, and Volume columns\n",
        "\n",
        "# Creating a list of dates for the predictions\n",
        "last_date = data.index[-1]"
      ],
      "metadata": {
        "id": "zSMTOnPBy-GF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_day = last_date + pd.Timedelta(days=1)\n",
        "prediction_dates = pd.date_range(start=next_day, periods=4)\n",
        "\n",
        "# Assuming 'predicted_prices' is your list of predicted prices for the next 4 days\n",
        "predictions_df = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])\n",
        "\n",
        "# Plotting the actual data with mplfinance\n",
        "mpf.plot(data, type='candle', style='charles', volume=True)\n",
        "\n",
        "# Overlaying the predicted data\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(predictions_df.index, predictions_df['Close'], linestyle='dashed', marker='o', color='red')\n",
        "\n",
        "plt.title(\"AAPL Stock Price with Predicted Next 4 Days\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eWSuQhRKRPIl",
        "outputId": "32c3e042-e95b-4935-d645-882d7f40083b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'int' and 'Timedelta'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-dab204191662>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_date\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming 'predicted_prices' is your list of predicted prices for the next 4 days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'Timedelta'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsKwmv2QP5hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9hjnhSnKPtz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mplfinance as mpf\n",
        "import matplotlib.dates as mpl_dates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch the latest 60 days of AAPL stock data\n",
        "data = yf.download('AAPL', period='64d', interval='1d') # Fetch 64 days to display last 60 days in the chart\n",
        "\n",
        "# Select 'Close' price and scale it\n",
        "closing_prices = data['Close'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(closing_prices)\n",
        "\n",
        "# Predict the next 4 days iteratively\n",
        "predicted_prices = []\n",
        "current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days\n",
        "\n",
        "for i in range(4):  # Predicting 4 days\n",
        "    next_prediction = model.predict(current_batch)\n",
        "    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
        "    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
        "    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
        "\n",
        "# Creating a list of dates for the predictions\n",
        "last_date = data.index[-1]\n",
        "next_day = last_date + pd.Timedelta(days=1)\n",
        "prediction_dates = pd.date_range(start=next_day, periods=4)\n",
        "\n",
        "# Adding predictions to the DataFrame\n",
        "predicted_data = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])\n",
        "\n",
        "# Combining both actual and predicted data\n",
        "combined_data = pd.concat([data['Close'], predicted_data['Close']])\n",
        "combined_data = combined_data[-64:] # Last 60 days of actual data + 4 days of predictions\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(combined_data, linestyle='-', marker='o', color='blue')\n",
        "plt.title(\"AAPL Stock Price: Last 60 Days and Next 4 Days Predicted\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M8ef1hgmz9Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mplfinance as mpf\n",
        "import matplotlib.dates as mpl_dates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch the latest 60 days of AAPL stock data\n",
        "data = yf.download('AAPL', period='64d', interval='1d') # Fetch 64 days to display last 60 days in the chart\n",
        "\n",
        "# Select 'Close' price and scale it\n",
        "closing_prices = data['Close'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(closing_prices)\n",
        "\n",
        "# Predict the next 4 days iteratively\n",
        "predicted_prices = []\n",
        "current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days\n",
        "\n",
        "for i in range(4):  # Predicting 4 days\n",
        "    next_prediction = model.predict(current_batch)\n",
        "    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
        "    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
        "    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
        "\n",
        "# Creating a list of dates for the predictions\n",
        "last_date = data.index[-1]\n",
        "next_day = last_date + pd.Timedelta(days=1)\n",
        "prediction_dates = pd.date_range(start=next_day, periods=4)\n",
        "\n",
        "# Adding predictions to the DataFrame\n",
        "predicted_data = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])\n",
        "\n",
        "# Combining both actual and predicted data\n",
        "combined_data = pd.concat([data['Close'], predicted_data['Close']])\n",
        "combined_data = combined_data[-64:] # Last 60 days of actual data + 4 days of predictions\n",
        "\n",
        "# Plotting the actual data\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(data.index[-60:], data['Close'][-60:], linestyle='-', marker='o', color='blue', label='Actual Data')\n",
        "\n",
        "# Plotting the predicted data\n",
        "plt.plot(prediction_dates, predicted_prices, linestyle='-', marker='o', color='red', label='Predicted Data')\n",
        "\n",
        "plt.title(\"AAPL Stock Price: Last 60 Days and Next 4 Days Predicted\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vla8lKTp0NPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def predict_stock_price(input_date):\n",
        "    # Check if the input date is a valid date format\n",
        "    try:\n",
        "        input_date = pd.to_datetime(input_date)\n",
        "    except ValueError:\n",
        "        print(\"Invalid Date Format. Please enter date in YYYY-MM-DD format.\")\n",
        "        return\n",
        "\n",
        "    # Fetch data from yfinance\n",
        "    end_date = input_date\n",
        "    start_date = input_date - timedelta(days=90)  # Fetch more days to ensure we have 60 trading days\n",
        "    data = yf.download('AAPL', start=start_date, end=end_date)\n",
        "\n",
        "    if len(data) < 60:\n",
        "        print(\"Not enough historical data to make a prediction. Try an earlier date.\")\n",
        "        return\n",
        "\n",
        "    # Prepare the data\n",
        "    closing_prices = data['Close'].values[-60:]  # Last 60 days\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(closing_prices.reshape(-1, 1))\n",
        "\n",
        "    # Make predictions\n",
        "    predicted_prices = []\n",
        "    current_batch = scaled_data.reshape(1, 60, 1)\n",
        "\n",
        "    for i in range(4):  # Predicting 4 days\n",
        "        next_prediction = model.predict(current_batch)\n",
        "        next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
        "        current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
        "        predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
        "\n",
        "    # Output the predictions\n",
        "    for i, price in enumerate(predicted_prices, 1):\n",
        "        print(f\"Day {i} prediction: {price}\")\n",
        "\n",
        "# Example use\n",
        "user_input = input(\"Enter a date (YYYY-MM-DD) to predict AAPL stock for the next 4 days: \")\n",
        "predict_stock_price(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1i6mOTjHI4q",
        "outputId": "b5690ccb-60e8-48ed-d855-9e3cad7711e5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a date (YYYY-MM-DD) to predict AAPL stock for the next 4 days: 2024-04-29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Day 1 prediction: 169.30319213867188\n",
            "Day 2 prediction: 170.191650390625\n",
            "Day 3 prediction: 171.6841583251953\n",
            "Day 4 prediction: 173.26043701171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POWvjg2FAvKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKeG5NXsCdi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aapl_data.head(1)"
      ],
      "metadata": {
        "id": "LD6vooP1CdsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aapl_data.tail(1)"
      ],
      "metadata": {
        "id": "2lEJFbb7Cg1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4kBAqZBUEDBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "id": "Ez0Vg102CjH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(1)"
      ],
      "metadata": {
        "id": "3H_WxfHEClvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nG7cBcOBCnNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}